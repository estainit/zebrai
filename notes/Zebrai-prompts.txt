I want to write a trancriptor which accepts different languages (italian, persian, english, turkish) voice and save both the original voice and the transcriptions in database, also translate the trasnscription to english and save the translation as well, also translate from english to Third language (italian, persian, turkish, Arabick, etc) and return this translation to frontend.
i need this app works on live stream. i want to use it in a meeting where different person talks in different languages, but the output of frontend (the translated text or audio stream) will be costumizable for each participant. e.g. a participiant prefers to listen in english but have the text in persian.
i call this project Zebrai, please remember this name for later references.
so, lets go step by step, for Zebrai i have a react frontend which makes audio stream to python backend. should i make audio chunks and transcript chunk by chunk? what size (in byte) or length (in seconds) will be good? for the sake of accuracy should i transcript one chunck and re-transcript chunk n-1 plus chunk n? or some other strategy you suggest? same questions for translation. what is the best practice?

